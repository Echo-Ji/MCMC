{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tfe = tf.contrib.eager\\ntry:\\n    tfe.enable_eager_execution()\\nexcept ValueError:\\n    pass\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, pickle, math, warnings, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "'''tfe = tf.contrib.eager\n",
    "try:\n",
    "    tfe.enable_eager_execution()\n",
    "except ValueError:\n",
    "    pass\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n",
    "tfdtype = tf.float32\n",
    "npdtype = np.float32\n",
    "tfnn = tf.nn\n",
    "names = locals()\n",
    "\n",
    "# SMC参数设置\n",
    "J = 10    #迭代轮数\n",
    "B = 10 #10**4 #并行样本数\n",
    "K = 16    #每次MH的轮数\n",
    "\n",
    "layer_size = [8, 7, 10, 1]\n",
    "l2_norm = 0.0003\n",
    "\n",
    "# 数据导入以及标准化处理\n",
    "features = ['fixed acidity','volatile acidity','residual sugar','chlorides','free sulfur dioxide','density','pH','sulphates']\n",
    "df = pd.read_csv('../winequality-white.csv', sep=';')\n",
    "X = df[features].values\n",
    "y = (df.quality >= 7).values\n",
    "\n",
    "X = StandardScaler().fit_transform(X).astype(npdtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def samples_init():\n",
    "    # fill in weights and biases with random normal\n",
    "    len_layer = len(layer_size)\n",
    "    # create empty list for weights and biases\n",
    "    for i in range(1, len_layer):\n",
    "        names['w_'+str(i)+'s'] = []\n",
    "        names['b_'+str(i)+'s'] = []\n",
    "    samples = []\n",
    "    samples_append = samples.append\n",
    "    for b in range(B):\n",
    "        theta = []\n",
    "        for s1, s2 in zip(layer_size[:-1], layer_size[1:]):\n",
    "            theta.append(weight_init([s1, s2]))\n",
    "            theta.append(bias_init([s2]))\n",
    "        samples_append(np.array(theta))\n",
    "    return np.array(samples)\n",
    "\n",
    "# 网络权重初始化\n",
    "def weight_init(shape, mean=0.0, stddev=10.0):\n",
    "    weights = tf.truncated_normal(shape, mean=mean, stddev=stddev, dtype=tfdtype)\n",
    "    return tf.Variable(weights)\n",
    "\n",
    "# 偏置的初始化\n",
    "def bias_init(shape, mean=0.0, stddev=10.0):\n",
    "    biases = tf.random_normal(shape, mean=mean, stddev=stddev, dtype=tfdtype)\n",
    "    return tf.Variable(biases)\n",
    "\n",
    "# log likelihood function\n",
    "def log_likeihood_fn(w_1, b_1, w_2, b_2, w_3, b_3):\n",
    "    print(w_1)\n",
    "    print(b_1)\n",
    "    layer_1 = tfnn.relu(tf.matmul(X, w_1) + b_1)\n",
    "    layer_2 = tfnn.relu(tf.matmul(layer_1, w_2) + b_2)\n",
    "    layer_3 = -tfnn.sigmoid_cross_entropy_with_logits(\n",
    "        labels=y, \n",
    "        logits=(tf.matmul(layer_2, w_3) + b_3))\n",
    "    print(type(tf.reduce_mean(layer_3)))\n",
    "    return tf.reduce_sum(layer_3)\n",
    "    \n",
    "# target log probability function \n",
    "# issue: no phi_j\n",
    "def smc_log_prob_fn(w_1, b_1, w_2, b_2, w_3, b_3):\n",
    "    # compute log prior ratio\n",
    "    pri = 0\n",
    "    pri += tf.reduce_sum(w_1 * w_1)\n",
    "    pri += tf.reduce_sum(w_2 * w_2)\n",
    "    pri += tf.reduce_sum(w_3 * w_3)\n",
    "    pri += tf.reduce_sum(b_1 * b_1)\n",
    "    pri += tf.reduce_sum(b_2 * b_2)\n",
    "    pri += tf.reduce_sum(b_3 * b_3)\n",
    "    \n",
    "    # compute log likelihood\n",
    "    layer_1 = tfnn.relu(tf.matmul(X, w_1) + b_1)\n",
    "    layer_2 = tfnn.relu(tf.matmul(layer_1, w_2) + b_2)\n",
    "    layer_3 = -tfnn.sigmoid_cross_entropy_with_logits(\n",
    "        labels=y, \n",
    "        logits=(tf.matmul(layer_2, w_3) + b_3))\n",
    "    return tf.reduce_sum(layer3) + 0.0003 * pri\n",
    "\n",
    "def draw_from_multinomial(thetas, p):\n",
    "    dist = tfd.Multinomial(total_count=n, probs=p)\n",
    "    idxes = dist.samples(1)[0]\n",
    "    with tf.Session() as sess:\n",
    "        idxes = sess.run(idxes)\n",
    "    idxes = idxes.astype(np.int32)\n",
    "    res = []\n",
    "    res_append = res.append\n",
    "    for i in range(B):\n",
    "        while(idxes[i] != 0):\n",
    "            res_append(thetas[i])\n",
    "            idxes[i] -= 1\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smc_body(samples, phi, w, j):\n",
    "    start = time.time()\n",
    "    # Correction\n",
    "    v = []\n",
    "    for (w1, b1, w2, b2, w3, b3) in samples:\n",
    "        v.append(log_likeihood_fn(w1, b1, w2, b2, w3, b3))\n",
    "    v = tf.exp((phi[j] - phi[j-1]) * np.array(v))\n",
    "    \n",
    "    # Selection\n",
    "    w = B * v * w / tf.reduce_sum(v * w)\n",
    "    ESS = B**2 / tf.reduce_sum(w * w)\n",
    "    \n",
    "    if ESS > 0.5*B:\n",
    "        var_samples = deepcopy(samples)\n",
    "    else:\n",
    "        #var_w_1s, var_b_1s, var_w_2s, var_b_2s,var_w_3s, var_b_3s =  draw_from_multinomial(w_1s, b_1s, w_2s, b_2s, w_3s, b_3s, w, n)\n",
    "        var_samples = draw_from_multinomial(samples, w)\n",
    "        \n",
    "    # RWM sampling\n",
    "    samples, _ = tfp.mcmc.sample_chain(\n",
    "      num_results=K,\n",
    "      current_state=var_samples, #the first dimension is B\n",
    "      kernel=tfp.mcmc.RandomWalkMetropolis(\n",
    "         target_log_prob_fn=smc_log_prob_fn,\n",
    "         seed=42),\n",
    "      num_burnin_steps=0,\n",
    "      parallel_iterations=10)  # For determinism.\n",
    "    print ('轮数：',j, '总时间：', time.time()-start)\n",
    "    with open('./smc4/'+str(j),'wb') as f:\n",
    "            pickle.dump(samples, f)\n",
    "    return samples[-1], phi, w, j+1\n",
    "\n",
    "def smc_cond(samples, phi, w, j):\n",
    "    return j<J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smc(samples):\n",
    "    n = len(X)\n",
    "    w = np.ones(shape=B)\n",
    "    phi = np.linspace(0, 1, J)**2\n",
    "    j = tf.constant(0)\n",
    "    samples, phi, w, j = tf.while_loop(cond=smc_cond, body=smc_body, loop_vars=[samples, phi, w, j])\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(samples)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got <tf.Variable 'Variable:0' shape=(8, 7) dtype=float32_ref>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b5dc549d9e71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-5527ee1c3bbb>\u001b[0m in \u001b[0;36msmc\u001b[0;34m(samples)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhile_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmc_cond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmc_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jjh/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3272\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 3274\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   3275\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jjh/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2984\u001b[0m     loop_vars = nest.map_structure(_convert_tensorarray_to_flow,\n\u001b[1;32m   2985\u001b[0m                                    nest.flatten(loop_vars))\n\u001b[0;32m-> 2986\u001b[0;31m     \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_n_to_tensor_or_indexed_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jjh/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_n_to_tensor_or_indexed_slices\u001b[0;34m(values, dtype, name)\u001b[0m\n\u001b[1;32m   1373\u001b[0m   \"\"\"\n\u001b[1;32m   1374\u001b[0m   return internal_convert_n_to_tensor_or_indexed_slices(\n\u001b[0;32m-> 1375\u001b[0;31m       values=values, dtype=dtype, name=name, as_ref=False)\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jjh/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_n_to_tensor_or_indexed_slices\u001b[0;34m(values, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1344\u001b[0m       ret.append(\n\u001b[1;32m   1345\u001b[0m           internal_convert_to_tensor_or_indexed_slices(\n\u001b[0;32m-> 1346\u001b[0;31m               value, dtype=dtype, name=n, as_ref=as_ref))\n\u001b[0m\u001b[1;32m   1347\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jjh/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor_or_indexed_slices\u001b[0;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1303\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     return internal_convert_to_tensor(\n\u001b[0;32m-> 1305\u001b[0;31m         value, dtype=dtype, name=name, as_ref=as_ref)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jjh/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jjh/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    226\u001b[0m                                          as_ref=False):\n\u001b[1;32m    227\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jjh/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    205\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    206\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 207\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    208\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/home/jjh/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    540\u001b[0m     raise TypeError(\n\u001b[1;32m    541\u001b[0m         \"Element type not supported in TensorProto: %s\" % numpy_dtype.name)\n\u001b[0;32m--> 542\u001b[0;31m   \u001b[0mappend_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_proto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtensorflow/python/framework/fast_tensor_util.pyx\u001b[0m in \u001b[0;36mtensorflow.python.framework.fast_tensor_util.AppendObjectArrayToTensorProto\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/jjh/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 61\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got <tf.Variable 'Variable:0' shape=(8, 7) dtype=float32_ref>"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":    \n",
    "    samples = samples_init()\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "    smc(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
