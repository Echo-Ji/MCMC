{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, pickle, math, warnings, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "tfe = tf.contrib.eager\n",
    "try:\n",
    "    tfe.enable_eager_execution()\n",
    "except ValueError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n",
    "tfdtype = tf.float32\n",
    "npdtype = np.float32\n",
    "tfnn = tf.nn\n",
    "names = locals()\n",
    "\n",
    "# SMC参数设置\n",
    "J = 10    #迭代轮数\n",
    "B = 10 #10**4 #并行样本数\n",
    "K = 16    #每次MH的轮数\n",
    "\n",
    "layer_size = [8, 7, 10, 1]\n",
    "l2_norm = 0.0003\n",
    "\n",
    "# 数据导入以及标准化处理\n",
    "features = ['fixed acidity','volatile acidity','residual sugar','chlorides','free sulfur dioxide','density','pH','sulphates']\n",
    "df = pd.read_csv('../winequality-white.csv', sep=';')\n",
    "X = df[features].values\n",
    "y = (df.quality >= 7).values\n",
    "\n",
    "X = StandardScaler().fit_transform(X).astype(npdtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''def samples_init(w_1s, b_1s, w_2s, b_2s, w_3s, b_3s):\n",
    "    # fill in weights and biases with random normal\n",
    "    for b in range(B):\n",
    "        i = 1\n",
    "        for s1, s2 in zip(layer_size[:-1], layer_size[1:]):\n",
    "            names['w_'+str(i)+'s'].append(weight_init([s1, s2]))\n",
    "            names['b_'+str(i)+'s'].append(bias_init([s2]))\n",
    "            i += 1\n",
    "    return #w_1s, b_1s, w_2s, b_2s, w_3s, b_3s\n",
    "'''\n",
    "def samples_init():\n",
    "    # fill in weights and biases with random normal\n",
    "    len_layer = len(layer_size)\n",
    "    # create empty list for weights and biases\n",
    "    for i in range(1, len_layer):\n",
    "        names['w_'+str(i)+'s'] = []\n",
    "        names['b_'+str(i)+'s'] = []\n",
    "    samples = []\n",
    "    samples_append = samples.append\n",
    "    for b in range(B):\n",
    "        theta = []\n",
    "        for s1, s2 in zip(layer_size[:-1], layer_size[1:]):\n",
    "            theta.append(weight_init([s1, s2]))\n",
    "            theta.append(bias_init([s2]))\n",
    "        samples_append(np.array(theta))\n",
    "    return np.array(samples)\n",
    "\n",
    "# 网络权重初始化\n",
    "def weight_init(shape, mean=0.0, stddev=10.0):\n",
    "    weights = tf.truncated_normal(shape, mean=mean, stddev=stddev, dtype=tfdtype)\n",
    "    return tf.Variable(weights)\n",
    "\n",
    "# 偏置的初始化\n",
    "def bias_init(shape, mean=0.0, stddev=10.0):\n",
    "    biases = tf.random_normal(shape, mean=mean, stddev=stddev, dtype=tfdtype)\n",
    "    return tf.Variable(biases)\n",
    "\n",
    "# log likelihood function\n",
    "def log_likeihood_fn(w_1, b_1, w_2, b_2, w_3, b_3):\n",
    "    print(w_1)\n",
    "    print(b_1)\n",
    "    layer_1 = tfnn.relu(tf.matmul(X, w_1) + b_1)\n",
    "    layer_2 = tfnn.relu(tf.matmul(layer_1, w_2) + b_2)\n",
    "    layer_3 = -tfnn.sigmoid_cross_entropy_with_logits(\n",
    "        labels=y, \n",
    "        logits=(tf.matmul(layer_2, w_3) + b_3))\n",
    "    print(type(tf.reduce_mean(layer_3)))\n",
    "    return tf.reduce_sum(layer_3)\n",
    "    \n",
    "# target log probability function \n",
    "# issue: no phi_j\n",
    "def smc_log_prob_fn(w_1, b_1, w_2, b_2, w_3, b_3):\n",
    "    # compute log prior ratio\n",
    "    pri = 0\n",
    "    pri += tf.reduce_sum(w_1 * w_1)\n",
    "    pri += tf.reduce_sum(w_2 * w_2)\n",
    "    pri += tf.reduce_sum(w_3 * w_3)\n",
    "    pri += tf.reduce_sum(b_1 * b_1)\n",
    "    pri += tf.reduce_sum(b_2 * b_2)\n",
    "    pri += tf.reduce_sum(b_3 * b_3)\n",
    "    \n",
    "    # compute log likelihood\n",
    "    layer_1 = tfnn.relu(tf.matmul(X, w_1) + b_1)\n",
    "    layer_2 = tfnn.relu(tf.matmul(layer_1, w_2) + b_2)\n",
    "    layer_3 = -tfnn.sigmoid_cross_entropy_with_logits(\n",
    "        labels=y, \n",
    "        logits=(tf.matmul(layer_2, w_3) + b_3))\n",
    "    return tf.reduce_sum(layer3) + 0.0003 * pri\n",
    "\n",
    "def draw_from_multinomial(thetas, p):\n",
    "    dist = tfd.Multinomial(total_count=n, probs=p)\n",
    "    idxes = dist.samples(1)[0]\n",
    "    with tf.Session() as sess:\n",
    "        idxes = sess.run(idxes)\n",
    "    idxes = idxes.astype(np.int32)\n",
    "    '''var_w_1s = []\n",
    "    var_b_1s = [] \n",
    "    var_w_2s = []\n",
    "    var_b_2s = [] \n",
    "    var_w_3s = []\n",
    "    var_b_3s = []\n",
    "    for i in range(B):\n",
    "        while(samples[i] != 0):\n",
    "            \n",
    "            var_w_1s.append(w_1s[i])\n",
    "            var_b_1s.append(b_1s[i])\n",
    "            var_w_2s.append(w_2s[i])\n",
    "            var_b_2s.append(b_2s[i])\n",
    "            var_w_3s.append(w_3s[i])\n",
    "            var_b_3s.append(b_3s[i])\n",
    "            samples[i] -= 1\n",
    "    return np.array(var_w_1s), np.array(var_b_1s), np.array(var_w_2s), np.array(var_b_2s), np.array(var_w_3s), np.array(var_b_3s)'''\n",
    "    res = []\n",
    "    res_append = res.append\n",
    "    for i in range(B):\n",
    "        while(idxes[i] != 0):\n",
    "            res_append(thetas[i])\n",
    "            idxes[i] -= 1\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def smc_body(w_1s, b_1s, w_2s, b_2s, w_3s, b_3s, j, n):\n",
    "    start = time.time()\n",
    "    # Correction\n",
    "    v = []\n",
    "    for (w1, b1, w2, b2, w3, b3) in zip(w_1s, b_1s, w_2s, b_2s, w_3s, b_3s):\n",
    "        v.append(log_likeihood_fn(w1, b1, w2, b2, w3, b3))\n",
    "    v = tf.exp((phi[j] - phi[j-1]) * np.array(v))\n",
    "    \n",
    "    # Selection\n",
    "    w = B * v * w / tf.reduce_sum(v * w)\n",
    "    ESS = B**2 / tf.reduce_sum(w * w)\n",
    "    \n",
    "    if ESS > 0.5*B:\n",
    "        var_w_1s = deepcopy(w_1s)\n",
    "        var_b_1s = deepcopy(b_1s) \n",
    "        var_w_2s = deepcopy(w_2s)\n",
    "        var_b_2s = deepcopy(b_2s) \n",
    "        var_w_3s = deepcopy(w_3s)\n",
    "        var_b_3s = deepcopy(b_3s)\n",
    "    else:\n",
    "        var_w_1s, var_b_1s, var_w_2s, var_b_2s,var_w_3s, var_b_3s =  draw_from_multinomial(w_1s, b_1s, w_2s, b_2s, w_3s, b_3s, w, n)\n",
    "        \n",
    "    # RWM sampling\n",
    "    init_state = [var_w_1s, var_b_1s, var_w_2s, var_b_2s,var_w_3s, var_b_3s]\n",
    "    samples, _ = tfp.mcmc.sample_chain(\n",
    "      num_results=K,\n",
    "      current_state=init_state, #the first dimension is B\n",
    "      kernel=tfp.mcmc.RandomWalkMetropolis(\n",
    "         target_log_prob_fn=smc_log_prob_fn,\n",
    "         seed=42),\n",
    "      num_burnin_steps=0,\n",
    "      parallel_iterations=10)  # For determinism.\n",
    "    print ('轮数：',j, '总时间：', time.time()-start)\n",
    "    return samples\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smc_body(samples, phi, w, j):\n",
    "    start = time.time()\n",
    "    # Correction\n",
    "    v = []\n",
    "    for (w1, b1, w2, b2, w3, b3) in samples:\n",
    "        v.append(log_likeihood_fn(w1, b1, w2, b2, w3, b3))\n",
    "    v = tf.exp((phi[j] - phi[j-1]) * np.array(v))\n",
    "    \n",
    "    # Selection\n",
    "    w = B * v * w / tf.reduce_sum(v * w)\n",
    "    ESS = B**2 / tf.reduce_sum(w * w)\n",
    "    \n",
    "    if ESS > 0.5*B:\n",
    "        var_samples = deepcopy(samples)\n",
    "    else:\n",
    "        #var_w_1s, var_b_1s, var_w_2s, var_b_2s,var_w_3s, var_b_3s =  draw_from_multinomial(w_1s, b_1s, w_2s, b_2s, w_3s, b_3s, w, n)\n",
    "        var_samples = draw_from_multinomial(samples, w)\n",
    "        \n",
    "    # RWM sampling\n",
    "    #init_state = [var_w_1s, var_b_1s, var_w_2s, var_b_2s,var_w_3s, var_b_3s]\n",
    "    samples, _ = tfp.mcmc.sample_chain(\n",
    "      num_results=K,\n",
    "      current_state=var_samples, #the first dimension is B\n",
    "      kernel=tfp.mcmc.RandomWalkMetropolis(\n",
    "         target_log_prob_fn=smc_log_prob_fn,\n",
    "         seed=42),\n",
    "      num_burnin_steps=0,\n",
    "      parallel_iterations=10)  # For determinism.\n",
    "    print ('轮数：',j, '总时间：', time.time()-start)\n",
    "    with open('./smc4/'+str(j),'wb') as f:\n",
    "            pickle.dump(samples, f)\n",
    "    return samples[-1], phi, w, j+1\n",
    "\n",
    "def smc_cond(samples, phi, w, j):\n",
    "    return j<J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smc(samples):\n",
    "    n = len(X)\n",
    "    w = np.ones(shape=B)\n",
    "    phi = np.linspace(0, 1, J)**2\n",
    "    j = tf.constant(0)\n",
    "    samples, phi, w, j = tf.while_loop(cond=smc_cond, body=smc_body, loop_vars=[phi, w, j])\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(samples)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'samples' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-996c822363e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-96d35f772261>\u001b[0m in \u001b[0;36msmc\u001b[0;34m(samples)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhile_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmc_cond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmc_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jjh/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3249\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3250\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d9195231720f>\u001b[0m in \u001b[0;36msmc_body\u001b[0;34m(phi, w, j)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Correction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_likeihood_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'samples' referenced before assignment"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":    \n",
    "    samples = samples_init()\n",
    "    smc(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(tf.while_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
